{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YvnIFjdvquD8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "content_image = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STYLE_IMAGE_NAME = 'IMAGE_7' #@param ['IMAGE_1', 'IMAGE_2', 'IMAGE_3', 'IMAGE_4', 'IMAGE_5', 'IMAGE_6', 'IMAGE_7', 'IMAGE_6', 'IMAGE_8', 'IMAGE_9', 'IMAGE_10', 'IMAGE_11', 'IMAGE_12', 'IMAGE_13', 'IMAGE_14']\n",
        "\n",
        "corresponding_url = {\n",
        "  'IMAGE_1':'https://upload.wikimedia.org/wikipedia/commons/0/0a/The_Great_Wave_off_Kanagawa.jpg',\n",
        "  'IMAGE_2':'https://upload.wikimedia.org/wikipedia/commons/b/b4/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg',\n",
        "  'IMAGE_3':'https://upload.wikimedia.org/wikipedia/commons/6/68/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg',\n",
        "  'IMAGE_4':'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg',\n",
        "  'IMAGE_5':'https://upload.wikimedia.org/wikipedia/commons/b/b7/JMW_Turner_-_Nantes_from_the_Ile_Feydeau.jpg',\n",
        "  'IMAGE_6':'https://upload.wikimedia.org/wikipedia/commons/c/c5/Edvard_Munch%2C_1893%2C_The_Scream%2C_oil%2C_tempera_and_pastel_on_cardboard%2C_91_x_73_cm%2C_National_Gallery_of_Norway.jpg',\n",
        "  'IMAGE_7':'https://upload.wikimedia.org/wikipedia/en/4/4c/Les_Demoiselles_d%27Avignon.jpg',\n",
        "  'IMAGE_8':'https://upload.wikimedia.org/wikipedia/en/3/3c/Pablo_Picasso%2C_1911-12%2C_Violon_%28Violin%29%2C_oil_on_canvas%2C_Kr%C3%B6ller-M%C3%BCller_Museum%2C_Otterlo%2C_Netherlands.jpg',\n",
        "  'IMAGE_9':'https://upload.wikimedia.org/wikipedia/en/7/7f/Pablo_Picasso%2C_1911%2C_Still_Life_with_a_Bottle_of_Rum%2C_oil_on_canvas%2C_61.3_x_50.5_cm%2C_Metropolitan_Museum_of_Art%2C_New_York.jpg',\n",
        "  'IMAGE_10':'https://upload.wikimedia.org/wikipedia/commons/3/36/Large_bonfire.jpg',\n",
        "  'IMAGE_11':'https://upload.wikimedia.org/wikipedia/commons/0/0d/Derkovits_Gyula_Woman_head_1922.jpg',\n",
        "  'IMAGE_12':'https://upload.wikimedia.org/wikipedia/commons/8/8e/Untitled_%28Still_life%29_%281913%29_-_Amadeo_Souza-Cardoso_%281887-1918%29_%2817385824283%29.jpg',\n",
        "  'IMAGE_13':'https://upload.wikimedia.org/wikipedia/commons/3/37/Derkovits_Gyula_Talig%C3%A1s_1920.jpg',\n",
        "  'IMAGE_14':'https://upload.wikimedia.org/wikipedia/commons/7/7d/Amadeo_de_Souza-Cardoso%2C_1915_-_Landscape_with_black_figure.jpg'\n",
        "}\n",
        "\n",
        "style_image_path = tf.keras.utils.get_file(STYLE_IMAGE_NAME + \".jpg\", corresponding_url[STYLE_IMAGE_NAME])"
      ],
      "metadata": {
        "id": "AuLwKZR6qwUw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates upload (for uploading images) and preview (for plotting the image)\n",
        "import ipywidgets\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "def button_click(change):\n",
        "    global content_image\n",
        "    print('\\n')\n",
        "    print(dir(uploader))\n",
        "    img = Image.open(io.BytesIO(uploader.data[-1]))\n",
        "    content_image = img\n",
        "    # display(img)\n",
        "    \n",
        "uploader = widgets.FileUpload()\n",
        "show_button = widgets.Button(description='Preview')\n",
        "show_button.on_click(button_click)\n",
        "\n",
        "widgets.VBox([widgets.Label(), uploader, show_button])"
      ],
      "metadata": {
        "id": "gbVZd3GPq1Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Opens the webcam so that we can click on the frame on which the style will be applied\n",
        "\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "VIDEO_HTML = \"\"\"\n",
        "<video autoplay\n",
        " width=%d height=%d style='cursor: pointer;'></video>\n",
        "<script>\n",
        "\n",
        "var video = document.querySelector('video')\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({ video: true })\n",
        "  .then(stream=> video.srcObject = stream)\n",
        "  \n",
        "var data = new Promise(resolve=>{\n",
        "  video.onclick = ()=>{\n",
        "    var canvas = document.createElement('canvas')\n",
        "    var [w,h] = [video.offsetWidth, video.offsetHeight]\n",
        "    canvas.width = w\n",
        "    canvas.height = h\n",
        "    canvas.getContext('2d')\n",
        "          .drawImage(video, 0, 0, w, h)\n",
        "    video.srcObject.getVideoTracks()[0].stop()\n",
        "    video.replaceWith(canvas)\n",
        "    resolve(canvas.toDataURL('image/jpeg', %f))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "def take_photo(filename='photo.jpg', quality=0, size=(800,600)):\n",
        "    global content_image\n",
        "    display(HTML(VIDEO_HTML % (size[0],size[1],quality)))\n",
        "    data = eval_js(\"data\")\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    f = io.BytesIO(binary)\n",
        "    content_image = Image.open(f)\n",
        "    print('\\nImage captured! ðŸ¤³')\n",
        "\n",
        "take_photo()"
      ],
      "metadata": {
        "id": "mzcVFkd-q1Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_content_img(image):\n",
        "  img = tf.convert_to_tensor(image)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  print(image.shape)\n",
        "  img = img[tf.newaxis, :]\n",
        "  return img  "
      ],
      "metadata": {
        "id": "IFDT8B6_rteK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_style_img(image):\n",
        "  img = tf.io.read_file(image)\n",
        "  img = tf.io.decode_image(img, channels=3)\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  img = img[tf.newaxis, :]\n",
        "  return img"
      ],
      "metadata": {
        "id": "9UpEpNW0q1MQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image, target_dim):\n",
        "  print(image.shape) # (1, 543, 966, 3)\n",
        "  shape = tf.cast(tf.shape(image)[1:-1], tf.float32)\n",
        "  print(shape)\n",
        "  short_dim = min(shape)\n",
        "  scale = target_dim / short_dim\n",
        "  print(scale)\n",
        "  new_shape = tf.cast(shape * scale, tf.int32)\n",
        "  print(new_shape)\n",
        "  image = tf.image.resize(image, new_shape)\n",
        "  print(image.shape)\n",
        "  image = tf.image.resize_with_crop_or_pad(image, target_dim, target_dim)\n",
        "  print(image.shape)\n",
        "  return image\n",
        "\n",
        "# (1, 543, 966, 3)\n",
        "# tf.Tensor([543. 966.], shape=(2,), dtype=float32)\n",
        "# tf.Tensor(0.70718235, shape=(), dtype=float32)\n",
        "# tf.Tensor([384 683], shape=(2,), dtype=int32)\n",
        "# (1, 384, 683, 3)\n",
        "# (1, 384, 384, 3)  "
      ],
      "metadata": {
        "id": "EPzj5aksq1OJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(image, title=None):\n",
        "  if len(image.shape) > 3:\n",
        "    image = tf.squeeze(image, axis=0)\n",
        "\n",
        "  plt.imshow(image)\n",
        "  if title:\n",
        "    plt.title(title)"
      ],
      "metadata": {
        "id": "azJ3HwIeryJC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(content_image)\n",
        "# print(\"--------------------------------------------\")\n",
        "content_image = np.array(content_image)\n",
        "# print(content_image)\n",
        "content_image = load_content_img(content_image)\n",
        "preprocessed_content_image = preprocess_image(content_image, 384)"
      ],
      "metadata": {
        "id": "dQy6IOiFr4qL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Preprocessing the content image...')\n",
        "print('Content image shape:', preprocessed_content_image.shape)"
      ],
      "metadata": {
        "id": "Vod9P1Ncr8Yr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca86cdf-ccf5-4f14-d450-22aec7c14384"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing the content images...\n",
            "Content image shape: (1, 384, 384, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = \"int8\" #@param [\"int8\", \"float16\"]\n",
        "source_image = preprocessed_content_image\n",
        "if model_type == \"float16\":\n",
        "    preprocessed_source_image = preprocess_image(source_image, target_dim=224) \n",
        "else:\n",
        "    preprocessed_source_image = preprocess_image(source_image, target_dim=512) \n",
        "preprocessed_source_image.shape"
      ],
      "metadata": {
        "id": "n-WJTNSNtEX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = {\n",
        "    \"float16\": \"lite-model_cartoongan_fp16_1.tflite\",\n",
        "    \"int8\": \"lite-model_cartoongan_int8_1.tflite\"\n",
        "}\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=model_dict[model_type])\n",
        "input_details = interpreter.get_input_details()\n",
        "\n",
        "\n",
        "interpreter.allocate_tensors()\n",
        "interpreter.set_tensor(input_details[0]['index'], preprocessed_source_image)\n",
        "interpreter.invoke()\n",
        "\n",
        "raw_prediction = interpreter.tensor(\n",
        "    interpreter.get_output_details()[0]['index'])()"
      ],
      "metadata": {
        "id": "38XEvJjDtHaF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = (np.squeeze(raw_prediction)+1.0)*127.5\n",
        "output = np.clip(output, 0, 255).astype(np.uint8)\n",
        "output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)"
      ],
      "metadata": {
        "id": "WqYq77sxtWnR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(preprocessed_content_image[0])\n",
        "plt.title('Source image')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(output)\n",
        "plt.title('Cartoonized image')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ulnxD9ErtZPB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}